{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"CS1219_HW_1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3.9.4 64-bit"},"language_info":{"name":"python","version":"3.9.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a8ca8af2f80b487cb479efacbe25e168":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":["widget-interact"],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_28d9d10e1b79451fa9f00a7e28a7c2e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5459e2c8f22c43388283225c98c4f5e7","IPY_MODEL_d9eb1ca00f8d4fb897b246133725bad2"]}},"28d9d10e1b79451fa9f00a7e28a7c2e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5459e2c8f22c43388283225c98c4f5e7":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_d08a18eac19745cda6710edded899d32","_dom_classes":[],"description":"n","step":1,"_model_name":"IntSliderModel","orientation":"horizontal","max":30,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":5,"continuous_update":true,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1bc81d4150d4aa4a682a9fa6d005c6d"}},"d9eb1ca00f8d4fb897b246133725bad2":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_view_name":"OutputView","msg_id":"","_dom_classes":[],"_model_name":"OutputModel","outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":"<Figure size 288x216 with 1 Axes>"},"metadata":{}}],"_view_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_view_count":null,"_view_module_version":"1.0.0","layout":"IPY_MODEL_f639023f25cb4400a46d44f8f8526d59","_model_module":"@jupyter-widgets/output"}},"d08a18eac19745cda6710edded899d32":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1bc81d4150d4aa4a682a9fa6d005c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f639023f25cb4400a46d44f8f8526d59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"}},"cells":[{"cell_type":"markdown","source":["# Homework Assignment 1 : Understanding Bias-Variance Tradeoff\n","---\n","---\n","\n","YOU MUST NOT MAKE CHANGES TO THIS DOCUMENT - IT WILL NOT BE SAVED. INSTEAD, MAKE A COPY OF THIS NOTEBOOK AND PLAY AROUND WITH IT THERE.\n","\n","Go Here: ```File --> Save a copy in Drive```\n","\n","You can use this notebook as a point of reference and submit your own code as well. "],"metadata":{"id":"b0qW7onyoF_S"}},{"cell_type":"code","execution_count":null,"source":["# @title Import Libraries\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import seaborn as sns\r\n","from matplotlib.colors import ListedColormap\r\n","\r\n","from sklearn import neighbors, datasets\r\n","from sklearn.linear_model import LinearRegression #regression\r\n","from sklearn.neighbors import KNeighborsRegressor #KNN\r\n","from sklearn.model_selection import train_test_split #splitting data into train and test sets\r\n","from sklearn import datasets #importing dummy data \r\n","from sklearn.metrics import mean_squared_error # to measure the error between predicted value and actual value\r\n","\r\n","from __future__ import print_function\r\n","from ipywidgets import interact, interactive, fixed, interact_manual\r\n","import ipywidgets as widgets\r\n","from sklearn.datasets import load_iris\r\n","\r\n","#======== added imports ===============\r\n","from sklearn.preprocessing import PolynomialFeatures\r\n","from sklearn.metrics import accuracy_score"],"outputs":[],"metadata":{"id":"qlTzlGyPd6s4","cellView":"form"}},{"cell_type":"code","execution_count":null,"source":["# @title Helper Functions: Data Generation\r\n","def get_points(set_type=\"exponential\", num_points=200):\r\n","  \"\"\"\r\n","  Function to generate data according to some chosen function (or distribution).\r\n","  params:\r\n","    set_type (string) : indicates the type of function you wish to generate points from.\r\n","                        this can be one of \"exponential\", \"line\", \"polynomial-n\", \"sine\", \"cosine\", \r\n","    num_points (int)  : parameter to set the number of points you want to generate. \r\n","\r\n","  returns:\r\n","    x (np.array)      : input space\r\n","    y (np.array)      : f(x) -> this is your oracle labeller function\r\n","  \"\"\"\r\n","\r\n","  # initializing\r\n","  x = np.linspace(-1, 1, num_points) # CHANGE DOMAIN HERE\r\n","  y = np.zeros_like(x)\r\n","\r\n","  if set_type == \"line\":\r\n","    # points from a line of the form y = m*x + c\r\n","    # change m, c to generate different lines\r\n","    m, c = 0.45, 2 # CHANGE HERE\r\n","    y = m * x + c  \r\n","  \r\n","  elif set_type == \"exponential\":\r\n","    # generates points from an exponential of the form y = a + b*exp(x)\r\n","    # change a, b to generate a different exponential\r\n","    a, b = 2, 3 # CHANGE HERE\r\n","    y = a * np.exp(x)\r\n","\r\n","  elif set_type == \"sine\":\r\n","    # generates points from an exponential of the form y = a + b*sin(x)\r\n","    # change a, b to generate different sine wave\r\n","    a, b = 2, 3 # CHANGE HERE\r\n","    y = a + b * np.sin(x)\r\n","      \r\n","  elif set_type == \"cosine\":\r\n","    # generates points from an exponential of the form y = a + b*cos(x)\r\n","    # change a, b to generate different cosine wave\r\n","    a, b = 2, 3 # CHANGE HERE\r\n","    y = a + b * np.cos(x)   \r\n","\r\n","  elif set_type == \"polynomial-n\":\r\n","    # generates points from a degree n polynomial of the form \r\n","    # y = a_0 + a_1*x + a_2*x^2 + ... + a_(n-1)*x^(n-1)\r\n","    \r\n","    np.random.seed(2021) # CHANGE RANDOM SEED TO SET DIFFERENT COEFFS\r\n","    n = 8 # CHANGE DEGREE OF POLYNOMIAL HERE\r\n","    coeffs = 3 * np.random.random_sample(n) # [a_(n-1), a_(n-2),..., a_2, a_1, a_0]\r\n","    y = np.polyval(coeffs, x)  \r\n","\r\n","\r\n","  #========= Added Function ======================= \r\n","\r\n","  elif set_type == \"tangent\":\r\n","    # generates points from an exponential of the form y = a + b*tan(x)\r\n","    # change a, b to generate different cosine wave\r\n","    a, b = 2, 3 # CHANGE HERE\r\n","    y = a + b * np.tan(x) \r\n","\r\n","  elif set_type == \"log\":\r\n","    # generates points from an exponential of the form y = a + b*tan(x)\r\n","    # change a, b to generate different cosine wave\r\n","    a = 1 # CHANGE HERE\r\n","    y = a + np.log2(x)   \r\n","\r\n","  else:\r\n","    raise Exception(\"Invalid argument to set_type.\")\r\n","\r\n","  # print(x.shape, y.shape) # always check shapes\r\n","  return x, y\r\n","\r\n","#--------------------------------------------------------------------------------------------------------\r\n","\r\n","def get_noise(num_points=200):\r\n","  \"\"\"\r\n","  Function to generate noise from a standard normal distribution.\r\n","  params: \r\n","    num_points (int) : number of points generated. \r\n","  \r\n","  returns: \r\n","    a numpy array of size num_points populated with samples from a standard normal distribution\r\n","  \"\"\"\r\n","  np.random.seed(2021)\r\n","  return np.random.normal(loc = 0.0, scale = 1.0, size = num_points)\r\n","\r\n","#--------------------------------------------------------------------------------------------------------\r\n","  \r\n","\r\n","def generate_noisy_data(x, y, noise):\r\n","  \"\"\"\r\n","  Function to add noise to the generated points. \r\n","  params: \r\n","    x, y (np.arrays) : points obtained using get_points() with a fixed num_points\r\n","    noise (np.array)  : points obtained using get_noise() with the same num_points as above\r\n","\r\n","  returns:\r\n","    data (np.array)   : noisy data, array of size num_points\r\n","\r\n","  \"\"\"\r\n","  assert x.shape[0] == y.shape[0] == noise.shape[0], \"number of elements in 'x', 'y' and 'noise' arrays do not match\"\r\n","\r\n","  y_ = y + noise\r\n","\r\n","  # uncomment to plot your data before and after adding noise\r\n","  plt.plot(x, y)\r\n","  plt.plot(x, y_)\r\n","\r\n","  data = (x, y_)\r\n","  # print(data.shape) # always check shapes\r\n","\r\n","  return data\r\n","\r\n","  #--------------------------------------------------------------------------------------------------------\r\n","\r\n"],"outputs":[],"metadata":{"id":"FHJMnEdx3Geo","cellView":"form"}},{"cell_type":"markdown","source":["## Data Generation\n","In class, we saw the importance of knowing where our data comes from. All our learning problems would cease to exist if we figured out the true distribution of the events in the world around us. In real life scenarios, we rarely have access to the full distribution of data. However, to study how learning algorithms perform on different learning tasks, we can generate some data and *pretend*  like we do not know anything about the data we have generated. And in continuation with the game of pretence, we will also try to *model* this data, to try and understand everything about it. The advantage here? Since we have access to the truth (since we generated the data, and thus we're the oracle too), we can evaluate how our learner performs. \n","\n","\\\\\n","\n","Now, for the **first step: generating data**. Above, we have provided a few helper functions for you that allow you to generate data points from various numerical functions. You have ample legroom to change the parameters, so feel free to experiment. Add your own generation models too, if you want to. **You should experiment with \"line\", \"exponential\" and \"polynomial-n\" at least for full points. The rest (and any other function experimented with will give you bonus points). After generating the data, fitting a model and estimating performance, you must put in your observations, backed by plots, into a pdf document and briefly explain what you observe in words.**"],"metadata":{"id":"jlBAtOnruX1Q"}},{"cell_type":"code","execution_count":null,"source":["# SET YOUR GLOBAL PARAMS FOR DATA GENERATION HERE\r\n","num_points = 100 # number of data points\r\n","set_type = \"log\"  # the function you want to simulate\r\n","\r\n","# use the above functions to \r\n","#   1. get points in the x, y plane according to a function of your choice\r\n","#   2. generate noise\r\n","#   3. add the two together to generate a dataset\r\n","\r\n","# YOUR CODE GOES HERE\r\n","x, y = get_points(set_type,num_points)\r\n","noise = get_noise(num_points)\r\n","data = generate_noisy_data(x,y,noise)\r\n","\r\n","# uncomment to see the final plot\r\n","\r\n","plt.scatter(data[0], data[1]) # clearly, data[0] = x, data[1] = y\r\n","plt.show()"],"outputs":[],"metadata":{"id":"t-OZjS6res0Y"}},{"cell_type":"code","execution_count":null,"source":["plt.plot(x,y)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["You have successfully generated data!\n","\n","\\\\\n","Now, we move on to **sampling**. Let's make the story clear again: We've generated some data according to some underlying rule, but going forward, we pretend we can only sample from this data, that is, **our window to this world are the small samples we can draw**. \n","\n","You can set the sample size below, and the number of samples you want to draw from the data. What you see below is in some senses, also called bootstrapping (we're sure you'll look it up.)"],"metadata":{"id":"xcR9FPr7UCX1"}},{"cell_type":"code","execution_count":null,"source":["#@title Helper Functions : Sampling, Test-Train Split\r\n","def sampler(data_df, sample_size):\r\n","  \"\"\"\r\n","  function to sample 'sample_size' number of elements from the passed dataframe\r\n","  params:\r\n","    data_df (pandas dataframe) : contains the data we generated, with x, y as columns\r\n","    sample_size (int)          : indicates the number of samples we wish to pick for the set you want to pick\r\n","\r\n","  returns:\r\n","    sample_set (pandas df)     : dataframe of the sample set, with x, y as columns\r\n","  \"\"\"\r\n","\r\n","  sample_set = data_df.sample(n = sample_size).reset_index(drop=\"True\")\r\n","  return sample_set\r\n","\r\n","def split(sample_set, fraction = 0.8):\r\n","  \"\"\"\r\n","  function that takes a sample set and returns test and train sets split according \r\n","  to a set fraction. Default split -> test:train :: 20:80\r\n","\r\n","  params: \r\n","    sample_set (pd dataframe) : contains x, y as columns respectively \r\n","    fraction  (float)         : specifies the fraction of samples you want in the test set\r\n","\r\n","  returns:\r\n","    a tuple (train_set, test_set)\r\n","  \"\"\"\r\n","  # sample_set_shuffled = sample_set.iloc[np.random.permutation(sample_set.index)].reset_index(drop=True)\r\n","  # print(sample_set_shuffled)\r\n","  # test_set = sample_set_shuffled.sample(frac=fraction).reset_index(drop=True)\r\n","  # train_set = sample_set_shuffled.drop(test_set).reset_index(drop=True)\r\n","\r\n","  train_set, test_set = train_test_split(sample_set, test_size=fraction)\r\n","\r\n","  return train_set, test_set"],"outputs":[],"metadata":{"id":"9mg8cN3hSgBx","cellView":"form"}},{"cell_type":"markdown","source":["## Sampling\n","\n","Use the helper functions given above to draw sample sets of a fixed size from your generated data. Once you finish that, your sample sets will be stored in a list named ``` sample_sets ``` and you can access individual sets using the syntax ```sample_sets[i]```. Feel free to add a few code cells and see what your sample sets look like. \n","\n"],"metadata":{"id":"1TnafPbW2QgL"}},{"cell_type":"code","execution_count":null,"source":["# SET PARAMS FOR SAMPLING HERE\r\n","sample_size = 100 # the number of samples you want to draw.\r\n","num_sample_sets = 2 # the number of sets you want to create, each with 'sample_size' elements\r\n","\r\n","# making a dataframe out of data\r\n","data = pd.DataFrame(data).transpose()\r\n","\r\n","# store all your samples in this list\r\n","sample_sets = list()\r\n","for i in range(num_sample_sets):\r\n","  #run sampler() on data to collect sample_size samples in each iteration\r\n","  df = sampler(data, sample_size)\r\n","  sample_sets.append(df)\r\n","print(sample_sets)"],"outputs":[],"metadata":{"id":"wI9DW1TjU-8N"}},{"cell_type":"markdown","source":["We have given you some custom functions to split your individual sample sets into testing and training sets. Below, you can choose to play around with these functions or use the methods shown in the following section to create test and train sets. Our data is stored as points on the $2$-$D$ plane, so we need to separate out the inputs (**x**, or sometimes **X**) and the labels (**y**) for each set. "],"metadata":{"id":"6cRo8pg44qCB"}},{"cell_type":"code","execution_count":null,"source":["# SET PARAMS FOR SPLIT HERE\r\n","fraction = 0.2\r\n","sample_set = sample_sets[0] #eg: sample_sets[1]\r\n","\r\n","train_set, test_set = split(sample_set, fraction)\r\n","# x_train, y_train = train_set[0], train_set[1] --> convert these to numpy arrays\r\n","# x_test, y_test = test_set[0], test_set[1]\r\n","print(\"Size Train set: {}\".format(train_set.shape))\r\n","print(\"Size Test set: {}\".format(test_set.shape))"],"outputs":[],"metadata":{"id":"KAiD8k87Y5dw"}},{"cell_type":"markdown","source":["## Regression\n","---\n","\n","In the previous sections, we generated and sampled from data. Now, we get to the actual fun part, where we try to 'fit' a model to the data. What do we mean by this? Think about the PAC learning scenario you were introduced to in class.\n","\n","\\\\\n","As far as we are concerned, the training data is the only thing our learner has access to. It learns about the underlying data distribution based on this, or forms hypotheses about what the labelling function is.  The learner will try to minimize \"empirical\" or observable risk (a.k.a the training error) using a hypothesis it has formed on the sample available to it. Now is a good time to refelct on what you learnt about good and bad sample sets, and how this can affect training. \n","\n","As an external jury, when we want to see how well our model is able to \"generalize\" to data it has never seen before, we use the test set. This evaluation will give you an idea about whether or not your learner has hypothesised a function that fits supremely to the training set but atrociously to anything else, or performs well in either case, or any variation in between. \n","\n","---\n","The learning model you will be using in the following section is **Regression**. We have performed regression below on a dummy dataset so that you can get a taste of how the functions need to be used. **Your task is to use the data you generated above, and perform regression analyses with varying parameters, on each kind of dataset, and write a detailed report of your observations, backed by plots.** When do you see the model perform best on the training set? Does that automatically mean it performs best on the test set? Are there any assumptions we are implicitly making about the test and training data and how do you think it affects the model's performance overall? "],"metadata":{"id":"XEBByvVCnDtN"}},{"cell_type":"code","execution_count":null,"source":["# @title Helper Function: Regression\r\n","# @markdown These functions just provide one way  and it is not mandatory to use (you can define your own).\r\n","\r\n","# def linear_reg(X_train,y_train,X_test,y_test):\r\n","#   '''\r\n","#   Implementing linear regression using the Sci-kit learn module.\r\n","#   This function takes in the following parameters:\r\n","#   X_train,y_train : (Input,Output) pairs, on which we fit a regression model\r\n","#   X_test,y_test   : (Input,Output) pairs unseen by the model which help us evaluate its performance\r\n","#   '''  \r\n","#   reg = LinearRegression().fit(X_train, y_train) #fitting the linear regression model\r\n","#   y_pred = reg.predict(X_test) # predicting the output on the basis of unseen inputs\r\n","#   error = mean_squared_error(y_test, y_pred)\r\n","#   print(\"Prediction Error: {}\" .format(error))\r\n","\r\n","\r\n","#   #training error\r\n","#   train_pred = reg.predict(X_train)\r\n","#   train_error = mean_squared_error(y_train,train_pred)\r\n","#   print(\"Training Error: {}\" .format(train_error))\r\n","#   # plt.style.use(\"ggplot\")\r\n","#   # plt.scatter(X_test, y_test,label='data') #plotting the test data\r\n","  \r\n","#   # plt.show()\r\n","\r\n","#   # plt.scatter(X_test,y_pred)\r\n","#   y = max(y_test)\r\n","#   y_= min(y_test)\r\n","#   x = np.linspace(y_,y,1000)\r\n","#   plt.figure(figsize=(15,10))\r\n","#   plt.scatter(y_test,y_pred)\r\n","#   # plt.plot(X_test, y_pred,label='prediction',color=\"purple\")   #plotting the curve using our predictions\r\n","\r\n","#   # plt.plot(x,x,\"g\")\r\n","#   plt.xlabel(\"Actual Value\")\r\n","#   plt.ylabel(\"Predicted Value\")\r\n","#   plt.title(\"Actual Vs Predicted values ({} function)\".format(set_type))\r\n","#   plt.show()\r\n","\r\n","# linear_reg(train_set[0].values.reshape(-1,1), train_set[1], test_set[0].values.reshape(-1,1), test_set[1])"],"outputs":[],"metadata":{"id":"n6SFIhWpnGNu","cellView":"form"}},{"cell_type":"code","execution_count":null,"source":["### Polymonial Regression\r\n","\r\n","def poly_reg(degree, x_train, y_train, x_test, y_test):\r\n","\t'''\r\n","\tfunction: poly_reg (Gives the polynomial regression for a set of data)\r\n","\t\tUsing PolymnomialFeatures and LinearRegression functions, fits a polynomial of degree n.  \r\n","\r\n","\t\tparm: \r\n","\t\t\t1> degree: degree of the polynomial you want to fit\r\n","\t\t\t2> x_train, y_train : training dataset\r\n","\t\t\t3> x_test, y_test: testing dataset\r\n","\t\t\r\n","\t\tretun: \r\n","\t\t\t1> training error and testing error\r\n","\t'''\r\n","\t\r\n","\tpoly_features = PolynomialFeatures(degree)\r\n","\r\n","\tpoly_x_train = poly_features.fit_transform(x_train)\r\n","\tpoly_x_test = poly_features.fit_transform(x_test)\r\n","\r\n","\tpoly_model = LinearRegression().fit(poly_x_train, y_train)\r\n","\r\n","\ty_test_pred = poly_model.predict(poly_x_test)  # predicting h(test_data)\r\n","\ty_train_pred = poly_model.predict(poly_x_train)  #predicting h(training_data)\r\n","\r\n","\ttest_error = mean_squared_error(y_test, y_test_pred)\r\n","\ttraining_error = mean_squared_error(y_train, y_train_pred)\r\n","\r\n","\r\n","\t#@Plotting\r\n","\t'''\r\n","\t\t1> Fitting polynomial on testing data: Gives an idea of overfitting and overfitting\r\n","\t\t2> Actual value (y_test) vs Predicted Value (y_test_pred): Gives and idea of bias and vairance\r\n","\t'''\r\n","\tfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,6), gridspec_kw={'width_ratios': [5, 3]})\r\n","\tfig.suptitle('Function: {} , Sample Size : {}'.format(set_type.capitalize(), sample_size))\r\n","\t\r\n","\t# plotting 1\r\n","\t#plotting training data \r\n","\tax1.scatter(x_train, y_train, label = \"Training Data (shape = {})\".format(train_set.shape), color='b')\r\n","\tax1.legend(loc='upper right')\r\n","\r\n","\t#plotting prediction function h(x) note: the predicted values need to be in ascending order\r\n","\tx_test_1d = np.ravel(x_train)   #convertin 2d array of x_test to 1d array\r\n","\tdf = pd.DataFrame({\"x_test\": x_test_1d, \"y_test_pred\": y_train_pred})\r\n","\tdf.sort_values(by=['x_test'], inplace=True)\r\n","\r\n","\tax1.plot(df.x_test, df.y_test_pred, label = \"Polynomial degree = {}\".format(degree), color='r')\r\n","\tax1.legend(loc='upper left')\r\n","\tax1.set_title(\"Polynomial fitting in training data\")\r\n","\r\n","\t#Poltting 2\r\n","\tax2.scatter(y_test_pred, y_test)\r\n","\t\r\n","\t# plotting line y = x\r\n","\ty = max(y_test)\r\n","\ty_= min(y_test)\r\n","\tx = np.linspace(y_,y,1000)\r\n","\tax2.plot(x,x, color = \"g\")\r\n","\r\n","\tax2.set_title(\"Actual Value vs Predicted Value\")\r\n","\r\n","\r\n","\t\r\n","\t# print(df)\r\n","\treturn test_error, training_error\r\n","\r\n","\r\n","poly_reg(degree=22, x_train=train_set[0].values.reshape(-1,1), y_train=train_set[1], x_test=test_set[0].values.reshape(-1,1), y_test=test_set[1])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#creating a dataframe for test error and training error with respect to a degree \r\n","error_df = pd.DataFrame(columns=[\"degree\", \"test_error\", \"training_error\"])\r\n","for i in range(1,21): # running poly_reg for degree i: from 1 to 20\r\n","\ttest_error, training_error = poly_reg(degree=i, x_train=train_set[0].values.reshape(-1,1), y_train=train_set[1], x_test=test_set[0].values.reshape(-1,1), y_test=test_set[1])\r\n","\terror_df.loc[i-1] = [i,test_error,training_error]\r\n","\r\n","error_df\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Plotting the training error and testing error \r\n","plt.plot( error_df.degree,error_df.training_error,label='train',color = 'r' )\r\n","\r\n","plt.plot( error_df.degree,error_df.test_error,label='test',color = 'b' )\r\n","plt.title(\"Training Error vs Testing Error (Sample Size = {})\".format(sample_size))\r\n","plt.xlabel(\"Degree\")\r\n","plt.ylabel(\"Error\")\r\n","plt.legend(bbox_to_anchor=(1.05, 1),loc=2,borderaxespad=0.)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["---\n","## K-Nearest Neighbours\n","\n","We look at a **multi-class classificaltion** problem next. For this, we use an algorithm called **K-Nearest Neighbours**. Different learning problems require different approaches to find meaningful hypothesis. For instance, if you use KNN on the data generated above, it would be meaningless, since we did not define any classes of data. You could try to apply it on the sets you generated there, and see for yourself the results. \n","\n","For this task, we use the **Iris dataset**, which allows for a multi-class classification problem. \n","Your task here is similar to the one above, where you vary the parameters of this model and see how it performs. Repeat the steps in the previous section. Figure out how to sample from the given dataset without using library functions. "],"metadata":{"id":"BCCvoyFBEYoY"}},{"cell_type":"code","execution_count":null,"source":["# @title Helper Functions: K-NN Clustering\r\n","\r\n","def knn(n):\r\n","\r\n","  iris = datasets.load_iris()\r\n","  X = iris.data[:, :2] # we only take the first two features. you can try it with more, but the visualization won't be 2d anymore\r\n","  Y = iris.target\r\n","\r\n","\r\n","  h = .02 # step size in the mesh\r\n","\r\n","  knn=neighbors.KNeighborsClassifier(n_neighbors=n)\r\n","\r\n","  # we create an instance of Neighbours Classifier and fit the data.\r\n","  knn.fit(X, Y)\r\n","\r\n","  # Plot the decision boundary. For that, we will asign a color to each\r\n","  # point in the mesh [x_min, m_max]x[y_min, y_max].\r\n","  x_min, x_max = X[:,0].min() - .5, X[:,0].max() + .5\r\n","  y_min, y_max = X[:,1].min() - .5, X[:,1].max() + .5\r\n","  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\r\n","  Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\r\n","  print(Z)\r\n","\r\n","  # Put the result into a color plot\r\n","  Z = Z.reshape(xx.shape)\r\n","  plt.style.use('ggplot')\r\n","  plt.figure(1, figsize=(12, 9))\r\n","  plt.set_cmap('BuPu')\r\n","  plt.pcolormesh(xx, yy, Z)\r\n","\r\n","  # pltot also the training points\r\n","  plt.scatter(X[:,0], X[:,1],c=Y,facecolors='none', edgecolors='r')\r\n","  plt.xlabel('Sepal length')\r\n","  plt.ylabel('Sepal width')\r\n","\r\n","  plt.xlim(xx.min(), xx.max())\r\n","  plt.ylim(yy.min(), yy.max())\r\n","  plt.xticks(())\r\n","  plt.yticks(())\r\n","  plt.show()\r\n"],"outputs":[],"metadata":{"id":"wjTCJH3M_8FP","cellView":"form"}},{"cell_type":"code","execution_count":null,"source":["# @title Run this widget to vary the k in the model and visualize what it does.\r\n","interact(knn, n=widgets.IntSlider(min=5, max=50, step=1, value=5))"],"outputs":[],"metadata":{"id":"jz7hDxr1tw1B","colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["a8ca8af2f80b487cb479efacbe25e168","28d9d10e1b79451fa9f00a7e28a7c2e8","5459e2c8f22c43388283225c98c4f5e7","d9eb1ca00f8d4fb897b246133725bad2","d08a18eac19745cda6710edded899d32","e1bc81d4150d4aa4a682a9fa6d005c6d","f639023f25cb4400a46d44f8f8526d59"]},"cellView":"form","executionInfo":{"status":"ok","timestamp":1631689648925,"user_tz":-330,"elapsed":1830,"user":{"displayName":"Yash More","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02090306686122893204"}},"outputId":"d5973dfa-833f-4464-b2ae-a3d4691a0169"}},{"cell_type":"code","execution_count":null,"source":["\r\n","\r\n","def knn_error(n):\r\n","\r\n","\t'''\r\n","\tfunction same as above but we split the sample data into training and testing sets\r\n","\t'''\r\n","\tiris = datasets.load_iris()\r\n","\tX = iris.data[:, :2] # we only take the first two features. you can try it with more, but the visualization won't be 2d anymore\r\n","\tY = iris.target\r\n","\r\n","\tX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\r\n","\t# h = .02 # step size in the mesh\r\n","\r\n","\tknn=neighbors.KNeighborsClassifier(n_neighbors=2)\r\n","\r\n","\t# we create an instance of Neighbours Classifier and fit the data.\r\n","\tknn.fit(X_train, y_train)\r\n","\r\n","\ty_test_predict = knn.predict(X_test)  #error with y_test\r\n","\ty_train_predict = knn.predict(X_train) #error with y_train\r\n","\r\n","\treturn y_train, y_train_predict, y_test, y_test_predict\r\n","\r\n","def get_error(real_arr, predict_arr):\r\n","\t'''\r\n","\tfunction: get_error\r\n","\r\n","\tparms: \r\n","\t\t1> real_arr: array of real values\r\n","\t\t2> predict_arr: array of predicted values\r\n","\r\n","\treturns: average of error\r\n","\t\tNote: error = 1 if f(x_i) != h(x_i) for i <= len(real_arr)\r\n","\t\t\t\t\t= 0 otherwise\r\n","\r\n","\t'''\r\n","\terror_counter = 0\r\n","\tfor i in range(len(real_arr)):\r\n","\t\tif real_arr[i] != predict_arr[i]:\r\n","\t\t\terror_counter += 1\r\n","\treturn error_counter/len(real_arr)\r\n","\r\n","#df for storing error for seprate values of n\r\n","knn_error_df = pd.DataFrame(columns=[\"n\", \"test_error\", \"training_error\"])\r\n","\r\n","for i in range(1,50):\r\n","\ty_train, y_train_predict, y_test, y_test_predict = knn_error(i)\r\n","\ttest_error = get_error(y_test, y_test_predict)\r\n","\ttrain_error = get_error(y_train, y_train_predict)\r\n","\tknn_error_df.loc[i-1] = [i,test_error,train_error]\r\n","\r\n","#Plotting the training error and testing error for knn classification\r\n","plt.figure(figsize=(15,9))\r\n","plt.plot(knn_error_df.n,knn_error_df.training_error,label='train',color = 'r' )\r\n","\r\n","plt.plot( knn_error_df.n,knn_error_df.test_error,label='test',color = 'b' )\r\n","plt.title(\"Training Error vs Testing Error\")\r\n","plt.xlabel(\"n\")\r\n","plt.ylabel(\"Error\")\r\n","plt.legend(bbox_to_anchor=(1.05, 1),loc=2,borderaxespad=0.)\r\n","\r\n","\r\n","\r\n","\r\n","\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from sklearn.model_selection import train_test_split\r\n","from sklearn.neighbors import KNeighborsClassifier \r\n","import matplotlib.pyplot as plt\r\n","\r\n","iris = datasets.load_iris()\r\n","X = iris.data[:, :2] # we only take the first two features. you can try it with more, but the visualization won't be 2d anymore\r\n","y = iris.target\r\n","# create a training and testing set (use your X and y)    \r\n","X_train,X_test, y_train, y_test= train_test_split(X,y,random_state=42, test_size=.3)\r\n","# create a set of k values and an empty list for training and testing accuracy scores\r\n","k_values=[i for i in range(1,50)]\r\n","train_scores=[]\r\n","test_scores=[]\r\n","# instantiate the model \r\n","k_nn=KNeighborsClassifier()\r\n","# create a for loop of models with different k's \r\n","\r\n","for k in k_values: \r\n","  k_nn.n_neighbors=k \r\n","  k_nn.fit(X_train,y_train)\r\n","  train_score=k_nn.score(X_train,y_train)\r\n","  test_score=k_nn.score(X_test,y_test)\r\n","  train_scores.append(train_score)\r\n","  test_scores.append(test_score)\r\n","\r\n","plt.plot(k_values,train_scores, color='red',label='Training Accuracy')\r\n","plt.plot(k_values,test_scores, color='blue',label='Testing Accuracy')\r\n","plt.xlabel('K values')\r\n","plt.ylabel('Accuracy Score')\r\n","plt.title('Performace Under Varying K Values')  "],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["---\n","---"],"metadata":{"id":"E96R61aqMYrv"}}]}